{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors classifier\n",
    "\n",
    "Implement the KNN classifier on the iris dataset using the Euclidean distance (L2-norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use load_iris to load in the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Iris target (i.e., label) names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Bunch type, with data either in an ndarray or a dataframe\n",
    "# A bunch object is a dictionary subclass that allows use of attribute notation for keys (e.g., bunch.key)\n",
    "iris_arr = load_iris()\n",
    "iris_df = load_iris(as_frame=True)\n",
    "\n",
    "print(type(iris_arr.data))\n",
    "print(type(iris_df.data))\n",
    "\n",
    "print('Iris target (i.e., label) names:', iris_arr.target_names)\n",
    "print('Iris feature names:', iris_df.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "X, Y = iris_arr.data, iris_arr.target\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using shuffle to allow for randomization of data\n",
    "\n",
    "Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 \n",
      "\n",
      "[ 14  98  75  16 131  56 141  44  29 120  94   5 102  51  78  42  92  66\n",
      "  31  35  90  84  77  40 125  99  33  19  73 146  91 135  69 128 114  48\n",
      "  53  28  54 108 112  17 119 103  58 118  18   4  45  59  39  36 117 139\n",
      " 107 132 126  85 122  95  11 113 123  12   2 104   6 127 110  65  55 144\n",
      " 138  46  62  74 116  93 100  89  10  34  32 124  38  83 111 149  27  23\n",
      "  67   9 130  97 105 145  87 148 109  64  15  82  41  80  52  26  76  43\n",
      "  24 136 121 143  49  21  70   3 142  30 147 106  47 115  13  88   8  81\n",
      "  60   0   1  57  22  61  63   7  86  96  68  50 101  20  25 134  71 129\n",
      "  79 133 137  72 140  37]\n",
      "<class 'numpy.ndarray'> \n",
      "\n",
      "Nice shuffle!\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed that generates the pseudo-randomization function\n",
    "np.random.seed(1)\n",
    "\n",
    "# Use permutation to shuffle the data\n",
    "print(X.shape[0], '\\n') # Number of rows\n",
    "\n",
    "# Set shuffle to be the randomized array of the values of 0-149 \n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "print(shuffle)\n",
    "print(type(shuffle), '\\n')\n",
    "X_shuffled, Y_shuffled = X[shuffle], Y[shuffle]\n",
    "\n",
    "# Check that the shuffling worked by using all to do a pairwise array element comparison\n",
    "if (X_shuffled[0] == X[114]).all and (Y_shuffled[0].all == Y[114]).all:\n",
    "    print(\"Nice shuffle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "\n",
      "[[3 4 5]\n",
      " [6 7 8]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "# FYI - When permutating on a multi-dimensional array, only the first index will shuffle\n",
    "arr = np.arange(9).reshape((3, 3))\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "permute = np.random.permutation(arr)\n",
    "print(permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train_data, train_labels = X_shuffled[:100], Y_shuffled[:100]\n",
    "test_data, test_labels = X_shuffled[100:], Y_shuffled[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the np.linalg.norm function to calculate the Ln Norm (default parameter of 2 = Euclidean distance)\n",
    "def EuclideanDistance(v1, v2):\n",
    "    return np.linalg.norm(v1 - v2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute all pairwise distances in the training data and store it in the list to plot on a histogram\n",
    "dists = []\n",
    "for i in range(len(train_data) - 1):\n",
    "    for j in range(i + 1, len(train_data)):\n",
    "        dist = EuclideanDistance(train_data[i], train_data[j])\n",
    "        dists.append(dist)\n",
    "        \n",
    "plt.hist(dists,100)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 1-NN class \n",
    "\n",
    "class NearestNeighbors:\n",
    "    # Initialize an instance of the class.\n",
    "    def __init__(self, metric=EuclideanDistance):\n",
    "        self.metric = metric\n",
    "    \n",
    "    # No training for Nearest Neighbors. Just store the data.\n",
    "    def fit(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    # Make predictions for each test example and return results.\n",
    "    def predict(self, test_data):\n",
    "        results = []\n",
    "        for item in test_data:\n",
    "            results.append(self._predict_item(item))\n",
    "        return results\n",
    "    \n",
    "    # Private function for making a single prediction.\n",
    "    def _predict_item(self, item):\n",
    "        best_dist, best_label = 1.0e10, None\n",
    "        for i in range(len(self.train_data)):\n",
    "            dist = self.metric(self.train_data[i], item)\n",
    "            if dist < best_dist:\n",
    "                best_label = self.train_labels[i]\n",
    "                best_dist = dist\n",
    "        return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  50  correct:  46  accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Create the NearestNeighbors object\n",
    "clf = NearestNeighbors()\n",
    "\n",
    "# Store the train data in the NearestNeighbors object\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "#  Predict the label for each data point in the test data based on the nearest neighbor from the train data\n",
    "preds = clf.predict(test_data)\n",
    "\n",
    "# For every prediction made, increment total by 1, and if the label was correct, increment correct by 1\n",
    "correct, total = 0, 0\n",
    "\n",
    "for pred, label in zip(preds, test_labels):\n",
    "    if pred == label: \n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "print ('total: %3d  correct: %3d  accuracy: %3.2f' %(total, correct, 1.0*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
